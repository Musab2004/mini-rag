{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio >installs.txt\n",
    "!pip install langchain >installs.txt\n",
    "!pip install pypdf >installs.txt\n",
    "!pip install --quiet langchain_experimental python-dotenv langchain_openai langchainhub >installs.txt\n",
    "!pip install chromadb >installs.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain import hub\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "import gradio as gr\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Processes a PDF document by loading, splitting, and embedding its text,\n",
    "    then storing the embeddings in a Chroma vector store.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The path to the PDF document to be processed.\n",
    "\n",
    "    Returns:\n",
    "        str: Confirmation message that the file is uploaded successfully.\n",
    "    \"\"\"\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pages = loader.load_and_split()\n",
    "    text_splitter = SemanticChunker(OpenAIEmbeddings())\n",
    "    texts = text_splitter.split_documents(pages)\n",
    "    vectorstore = Chroma.from_documents(documents=texts, embedding=OpenAIEmbeddings(), persist_directory=\"./chroma_db\")\n",
    "    vectorstore.persist()\n",
    "    return \"Your File is Uploaded Successfully!\"\n",
    "def rag_inference(question):\n",
    "    \"\"\"\n",
    "    Performs retrieval-augmented generation (RAG) to answer a question using\n",
    "    the document embeddings stored in a Chroma vector store.\n",
    "\n",
    "    Args:\n",
    "        question (str): The question to be answered.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated answer to the question.\n",
    "    \"\"\"\n",
    "    vectorstore = Chroma(persist_directory=\"./chroma_db\", embedding_function=OpenAIEmbeddings())\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": vectorstore._collection.count()})\n",
    "    llm = ChatOpenAI(api_key=api_key, model_name=\"gpt-4-turbo\", temperature=0)\n",
    "    prompt = hub.pull(\"hwchase17/react\")\n",
    "    tool_search = create_retriever_tool(\n",
    "        retriever=retriever,\n",
    "        name=\"search_document\",\n",
    "        description=\"Searches and returns excerpts from the document.\",\n",
    "    )\n",
    "    react_agent = create_react_agent(llm, [tool_search], prompt)\n",
    "    agent_executor = AgentExecutor(\n",
    "        agent=react_agent,\n",
    "        tools=[tool_search],\n",
    "        verbose=True,\n",
    "        handle_parsing_errors=True,\n",
    "        max_iterations=10\n",
    "    )\n",
    "    result = agent_executor.invoke({\"input\": question})\n",
    "    return result['output']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to understand the content of the document to answer the question about its topic.\n",
      "\n",
      "Action: search_document\n",
      "Action Input: \"document summary\"\u001b[0m\u001b[36;1m\u001b[1;3mCategories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\u001b[0m\u001b[32;1m\u001b[1;3mThe document appears to be a collection of summaries or abstracts from various academic papers related to advancements in language modeling, video and audio processing, 3D asset generation, and other applications of large language models (LLMs). Each entry provides details about the paper's title, authors, publication date, a brief description, and categories relevant to the research.\n",
      "\n",
      "Final Answer: The document is about recent advancements and research in various fields related to language modeling, video and audio processing, and other computational technologies, focusing on the development and application of large language models (LLMs).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def upload_and_process(pdf_file):\n",
    "    return process_pdf(pdf_file.name)\n",
    "\n",
    "def ask_question(question):\n",
    "    return rag_inference(question)\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## TASK-1 Mini RAg Bot\")\n",
    "\n",
    "    with gr.Row():\n",
    "        pdf_input = gr.File(label=\"Upload PDF\", type=\"filepath\", file_count=\"single\")\n",
    "        upload_button = gr.Button(\"Upload and Process\")\n",
    "        output_text = gr.Textbox()\n",
    "        upload_button.click(upload_and_process, inputs=pdf_input, outputs=output_text)\n",
    "    \n",
    "    with gr.Row():\n",
    "        question_input = gr.Textbox(label=\"Ask a question about the PDF\")\n",
    "        ask_button = gr.Button(\"Ask\")\n",
    "        answer_output = gr.Textbox(label=\"Answer\", interactive=False)\n",
    "        ask_button.click(ask_question, inputs=question_input, outputs=answer_output)\n",
    "\n",
    "demo.launch()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
