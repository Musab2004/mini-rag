{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio >installs.txt\n",
    "!pip install langchain >installs.txt\n",
    "!pip install pypdf >installs.txt\n",
    "!pip install --quiet langchain_experimental python-dotenv langchain_openai langchainhub >installs.txt\n",
    "!pip install chromadb >installs.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain import hub\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "import gradio as gr\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stored inn chroma db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musab/Task1_mini_rag/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "def process_pdf(pdf_path):\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        pages = loader.load_and_split()\n",
    "        text_splitter = SemanticChunker(OpenAIEmbeddings())\n",
    "        texts = text_splitter.split_documents(pages)\n",
    "        vectorstore = Chroma.from_documents(documents=texts, embedding = OpenAIEmbeddings(),persist_directory=\"./chroma_db\")\n",
    "        vectorstore.persist()\n",
    "        print(\"stored inn chroma db\")\n",
    "        retriever = vectorstore.as_retriever()\n",
    "        return \"Your File is Uploaded Successfully!\"\n",
    "chat_history = []\n",
    "\n",
    "\n",
    "retriever = process_pdf(\"RAG Input Doc.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rag_inference(question):\n",
    "    vectorstore = Chroma(persist_directory=\"./chroma_db\",embedding_function=OpenAIEmbeddings())\n",
    "    # print(\"vectorstore\",vectorstore._collection.count())\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": vectorstore._collection.count()})\n",
    "    llm = ChatOpenAI(api_key=api_key,model_name=\"gpt-4-turbo\", temperature=0)\n",
    "    prompt = hub.pull(\"hwchase17/react\")\n",
    "    tool_search = create_retriever_tool(\n",
    "        retriever=retriever,\n",
    "        name=\"search_document\",\n",
    "        description=\"Searches and returns excerpts from the document.\",\n",
    "    )\n",
    "    react_agent = create_react_agent(llm, [tool_search], prompt)\n",
    "    agent_executor = AgentExecutor(\n",
    "    agent=react_agent, \n",
    "    tools=[tool_search],\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations = 10 # useful when agent is stuck in a loop\n",
    "    )\n",
    "    # result=qa({\"query\": question})\n",
    "    result=agent_executor.invoke({\"input\": question})\n",
    "    return result['output'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo find the paper that received the highest number of stars per hour, I need to access data that shows the number of stars received by various papers and the time period over which they were accumulated.\n",
      "\n",
      "Action: search_document\n",
      "Action Input: \"papers with the highest number of stars per hour\"\u001b[0m\u001b[36;1m\u001b[1;3mStats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer based on the observed data.\n",
      "\n",
      "Final Answer: The paper titled \"MeshAnything: Artist-Created Mesh Generation with Autoregressive Transformers\" by buaacyw/meshanything, dated 14 Jun 2024, received the highest number of stars per hour at 5.09 stars/hour.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Which paper received the highest number of stars per hour?\n",
      "The paper titled \"MeshAnything: Artist-Created Mesh Generation with Autoregressive Transformers\" by buaacyw/meshanything, dated 14 Jun 2024, received the highest number of stars per hour at 5.09 stars/hour.\n",
      "-----------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find information about the 'MeshAnything' project to understand its focus.\n",
      "Action: search_document\n",
      "Action Input: \"MeshAnything project focus\"\u001b[0m\u001b[36;1m\u001b[1;3mTitle:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\u001b[0m\u001b[32;1m\u001b[1;3mThe search results indicate that the 'MeshAnything' project focuses on the creation of 3D assets through reconstruction and generation techniques. These assets are noted to match the quality of manually crafted assets, suggesting a potential for replacing traditional methods in certain applications. The project utilizes autoregressive transformers for this purpose.\n",
      "\n",
      "Final Answer: The focus of the 'MeshAnything' project is on generating high-quality 3D assets using autoregressive transformers, aiming to match and potentially replace manually crafted assets in various applications.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "What is the focus of the 'MeshAnything' project?\n",
      "The focus of the 'MeshAnything' project is on generating high-quality 3D assets using autoregressive transformers, aiming to match and potentially replace manually crafted assets in various applications.\n",
      "-----------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find a paper that discusses the integration of Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS). This is likely a topic at the intersection of artificial intelligence, specifically in areas related to game theory, decision-making processes, or advanced AI applications.\n",
      "\n",
      "Action: search_document\n",
      "Action Input: \"integration of Large Language Models with Monte Carlo Tree Search\"\u001b[0m\u001b[36;1m\u001b[1;3mTitle:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\u001b[0m\u001b[32;1m\u001b[1;3mThe search results include a paper titled \"Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-38B\" by trotsky1997/mathblackbox. This paper discusses the integration of Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), specifically designed to enhance performance in complex mathematical reasoning tasks. This seems to be the most relevant document based on the query.\n",
      "\n",
      "Final Answer: The paper discussing the integration of Large Language Models with Monte Carlo Tree Search is titled \"Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-38B\" by trotsky1997/mathblackbox.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Which paper discusses the integration of Large Language Models with Monte Carlo Tree Search?\n",
      "The paper discussing the integration of Large Language Models with Monte Carlo Tree Search is titled \"Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-38B\" by trotsky1997/mathblackbox.\n",
      "-----------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo answer the question about the advancements proposed in the 'VideoLLaMA 2' paper, I need to find specific information or summaries related to this paper. I will use the search_document function to retrieve relevant excerpts from documents that might contain information about the advancements in 'VideoLLaMA 2'.\n",
      "\n",
      "Action: search_document\n",
      "Action Input: 'VideoLLaMA 2 advancements'\u001b[0m\u001b[36;1m\u001b[1;3mCategories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\u001b[0m\u001b[32;1m\u001b[1;3mThe search results provide a detailed description of the advancements proposed in the 'VideoLLaMA 2' paper. The paper focuses on enhancing spatial-temporal modeling and audio understanding in video and audio-oriented tasks using a set of Video Large Language Models (Video-LLMs).\n",
      "\n",
      "Final Answer: The 'VideoLLaMA 2' paper proposes advancements in spatial-temporal modeling and audio understanding through the development of Video Large Language Models (Video-LLMs), aimed at improving performance in video and audio-oriented tasks.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "What advancements does the 'VideoLLaMA 2' paper propose?\n",
      "The 'VideoLLaMA 2' paper proposes advancements in spatial-temporal modeling and audio understanding through the development of Video Large Language Models (Video-LLMs), aimed at improving performance in video and audio-oriented tasks.\n",
      "-----------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo find the most recently published paper, I need to search through the documents available and identify the one with the latest publication date.\n",
      "\n",
      "Action: search_document\n",
      "Action Input: \"most recently published paper\"\u001b[0m\u001b[36;1m\u001b[1;3mCategories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: The most recently published paper is \"MeshAnything: Artist-Created Mesh Generation with Autoregressive Transformers\" by buaacyw/meshanything, published on 14 Jun 2024.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Which paper was published most recently?\n",
      "The most recently published paper is \"MeshAnything: Artist-Created Mesh Generation with Autoregressive Transformers\" by buaacyw/meshanything, published on 14 Jun 2024.\n",
      "-----------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find a paper that discusses language modeling and specifically addresses the aspect of scalability. To do this, I will use the search_document function to look for relevant documents or excerpts that mention both \"language modeling\" and \"scalability\".\n",
      "\n",
      "Action: search_document\n",
      "Action Input: \"language modeling scalability\"\u001b[0m\u001b[36;1m\u001b[1;3mStats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\u001b[0m\u001b[32;1m\u001b[1;3mThe search results provided a few papers, but the one that specifically addresses both language modeling and scalability is titled \"Scalable MatMul-free Language Modeling.\" This paper discusses the development of MatMul-free models that achieve performance comparable to state-of-the-art Transformers but require significantly less memory during inference, making them scalable up to at least 2.7 billion parameters.\n",
      "\n",
      "Final Answer: The paper titled \"Scalable MatMul-free Language Modeling\" by authors from ridgerchu/matmulfreellm, published on June 4, 2024, deals with language modeling and its scalability. It explores the development of MatMul-free models that are scalable and memory-efficient, capable of handling up to 2.7 billion parameters.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Identify a paper that deals with language modeling and its scalability.\n",
      "The paper titled \"Scalable MatMul-free Language Modeling\" by authors from ridgerchu/matmulfreellm, published on June 4, 2024, deals with language modeling and its scalability. It explores the development of MatMul-free models that are scalable and memory-efficient, capable of handling up to 2.7 billion parameters.\n",
      "-----------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find information about a specific paper that focuses on improving accuracy in Google-Proof Question Answering. This likely involves a paper or research that discusses methodologies or technologies aimed at enhancing the performance of question-answering systems in scenarios where the answers are not easily found through simple Google searches.\n",
      "\n",
      "Action: search_document\n",
      "Action Input: \"improving accuracy in Google-Proof Question Answering\"\u001b[0m\u001b[36;1m\u001b[1;3mStats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "\n",
      "Final Answer: The paper titled \"TextGrad: Automatic 'Differentiation' via Text\" by the zou-group aims at improving accuracy in Google-Proof Question Answering. This paper discusses how TextGrad enhances the zero-shot accuracy of GPT-4o specifically for Google-Proof Question Answering, among other applications.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Which paper aims at improving accuracy in Google-Proof Question Answering?\n",
      "The paper titled \"TextGrad: Automatic 'Differentiation' via Text\" by the zou-group aims at improving accuracy in Google-Proof Question Answering. This paper discusses how TextGrad enhances the zero-shot accuracy of GPT-4o specifically for Google-Proof Question Answering, among other applications.\n",
      "-----------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find out the specific categories covered by the paper titled 'TextGrad: Automatic \"Differentiation\" via Text'. To do this, I will search for excerpts from the document that mention this paper and its categories.\n",
      "\n",
      "Action: search_document\n",
      "Action Input: \"categories covered by the paper titled 'TextGrad: Automatic Differentiation via Text'\"\u001b[0m\u001b[36;1m\u001b[1;3mTitle:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: The paper titled \"TextGrad: Automatic 'Differentiation' via Text\" is categorized under \"Language Modelling.\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "List the categories covered by the paper titled 'TextGrad: Automatic \"Differentiation\" via Text'.\n",
      "The paper titled \"TextGrad: Automatic 'Differentiation' via Text\" is categorized under \"Language Modelling.\"\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"Which paper received the highest number of stars per hour?\",\n",
    "    \"What is the focus of the 'MeshAnything' project?\",\n",
    "    \"Which paper discusses the integration of Large Language Models with Monte Carlo Tree Search?\",\n",
    "    \"What advancements does the 'VideoLLaMA 2' paper propose?\",\n",
    "    \"Which paper was published most recently?\",\n",
    "    \"Identify a paper that deals with language modeling and its scalability.\",\n",
    "    \"Which paper aims at improving accuracy in Google-Proof Question Answering?\",\n",
    "    \"List the categories covered by the paper titled 'TextGrad: Automatic \\\"Differentiation\\\" via Text'.\"\n",
    "]\n",
    "all_results=[]\n",
    "for q in queries:\n",
    "    result=rag_inference(q)\n",
    "    print(q)\n",
    "    print(result)\n",
    "    print(\"-----------------------\")\n",
    "    \n",
    "    all_results.append({'query':q,'result':result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'query': 'Which paper received the highest number of stars per hour?', 'result': 'The paper titled \"MeshAnything: Artist-Created Mesh Generation with Autoregressive Transformers\" by buaacyw/meshanything, dated 14 Jun 2024, received the highest number of stars per hour at 5.09 stars/hour.'}, {'query': \"What is the focus of the 'MeshAnything' project?\", 'result': \"The focus of the 'MeshAnything' project is on generating high-quality 3D assets using autoregressive transformers, aiming to match and potentially replace manually crafted assets in various applications.\"}, {'query': 'Which paper discusses the integration of Large Language Models with Monte Carlo Tree Search?', 'result': 'The paper discussing the integration of Large Language Models with Monte Carlo Tree Search is titled \"Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-38B\" by trotsky1997/mathblackbox.'}, {'query': \"What advancements does the 'VideoLLaMA 2' paper propose?\", 'result': \"The 'VideoLLaMA 2' paper proposes advancements in spatial-temporal modeling and audio understanding through the development of Video Large Language Models (Video-LLMs), aimed at improving performance in video and audio-oriented tasks.\"}, {'query': 'Which paper was published most recently?', 'result': 'The most recently published paper is \"MeshAnything: Artist-Created Mesh Generation with Autoregressive Transformers\" by buaacyw/meshanything, published on 14 Jun 2024.'}, {'query': 'Identify a paper that deals with language modeling and its scalability.', 'result': 'The paper titled \"Scalable MatMul-free Language Modeling\" by authors from ridgerchu/matmulfreellm, published on June 4, 2024, deals with language modeling and its scalability. It explores the development of MatMul-free models that are scalable and memory-efficient, capable of handling up to 2.7 billion parameters.'}, {'query': 'Which paper aims at improving accuracy in Google-Proof Question Answering?', 'result': 'The paper titled \"TextGrad: Automatic \\'Differentiation\\' via Text\" by the zou-group aims at improving accuracy in Google-Proof Question Answering. This paper discusses how TextGrad enhances the zero-shot accuracy of GPT-4o specifically for Google-Proof Question Answering, among other applications.'}, {'query': 'List the categories covered by the paper titled \\'TextGrad: Automatic \"Differentiation\" via Text\\'.', 'result': 'The paper titled \"TextGrad: Automatic \\'Differentiation\\' via Text\" is categorized under \"Language Modelling.\"'}]\n"
     ]
    }
   ],
   "source": [
    "print(all_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
