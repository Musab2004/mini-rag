{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio >installs.txt\n",
    "!pip install langchain >installs.txt\n",
    "!pip install pypdf >installs.txt\n",
    "!pip install --quiet langchain_experimental python-dotenv langchain_openai langchainhub >installs.txt\n",
    "!pip install chromadb >installs.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain import hub\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "import gradio as gr\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Processes a PDF document by loading, splitting, and embedding its text,\n",
    "    then storing the embeddings in a Chroma vector store.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The path to the PDF document to be processed.\n",
    "\n",
    "    Returns:\n",
    "        str: Confirmation message that the file is uploaded successfully.\n",
    "    \"\"\"\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pages = loader.load_and_split()\n",
    "    text_splitter = SemanticChunker(OpenAIEmbeddings())\n",
    "    texts = text_splitter.split_documents(pages)\n",
    "    vectorstore = Chroma.from_documents(documents=texts, embedding=OpenAIEmbeddings(), persist_directory=\"./chroma_db\")\n",
    "    vectorstore.persist()\n",
    "    return \"Your File is Uploaded Successfully!\"\n",
    "def rag_inference(question):\n",
    "    \"\"\"\n",
    "    Performs retrieval-augmented generation (RAG) to answer a question using\n",
    "    the document embeddings stored in a Chroma vector store.\n",
    "\n",
    "    Args:\n",
    "        question (str): The question to be answered.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated answer to the question.\n",
    "    \"\"\"\n",
    "    vectorstore = Chroma(persist_directory=\"./chroma_db\", embedding_function=OpenAIEmbeddings())\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": vectorstore._collection.count()})\n",
    "    llm = ChatOpenAI(api_key=api_key, model_name=\"gpt-4-turbo\", temperature=0)\n",
    "    prompt = hub.pull(\"hwchase17/react\")\n",
    "    tool_search = create_retriever_tool(\n",
    "        retriever=retriever,\n",
    "        name=\"search_document\",\n",
    "        description=\"Searches and returns excerpts from the document.\",\n",
    "    )\n",
    "    react_agent = create_react_agent(llm, [tool_search], prompt)\n",
    "    agent_executor = AgentExecutor(\n",
    "        agent=react_agent,\n",
    "        tools=[tool_search],\n",
    "        verbose=True,\n",
    "        handle_parsing_errors=True,\n",
    "        max_iterations=10\n",
    "    )\n",
    "    result = agent_executor.invoke({\"input\": question})\n",
    "    return result['output']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to understand the content of the document to answer the question about its topic.\n",
      "\n",
      "Action: search_document\n",
      "Action Input: \"document summary\"\u001b[0m\u001b[36;1m\u001b[1;3mCategories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\u001b[0m\u001b[32;1m\u001b[1;3mThe document appears to be a collection of summaries or abstracts from various academic papers related to advancements in language modeling, video and audio processing, 3D asset generation, and other applications of large language models (LLMs). Each entry provides details about the paper's title, authors, publication date, a brief description, and categories relevant to the research.\n",
      "\n",
      "Final Answer: The document is about recent advancements and research in various fields related to language modeling, video and audio processing, and other computational technologies, focusing on the development and application of large language models (LLMs).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def upload_and_process(pdf_file):\n",
    "    return process_pdf(pdf_file.name)\n",
    "\n",
    "def ask_question(question):\n",
    "    return rag_inference(question)\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## TASK-1 Mini RAg Bot\")\n",
    "\n",
    "    with gr.Row():\n",
    "        pdf_input = gr.File(label=\"Upload PDF\", type=\"filepath\", file_count=\"single\")\n",
    "        upload_button = gr.Button(\"Upload and Process\")\n",
    "        output_text = gr.Textbox()\n",
    "        upload_button.click(upload_and_process, inputs=pdf_input, outputs=output_text)\n",
    "    \n",
    "    with gr.Row():\n",
    "        question_input = gr.Textbox(label=\"Ask a question about the PDF\")\n",
    "        ask_button = gr.Button(\"Ask\")\n",
    "        answer_output = gr.Textbox(label=\"Answer\", interactive=False)\n",
    "        ask_button.click(ask_question, inputs=question_input, outputs=answer_output)\n",
    "\n",
    "demo.launch()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find information about the paper that has received the highest number of stars per hour. This likely involves searching for data related to papers and their star ratings over time.\n",
      "\n",
      "Action: search_document\n",
      "Action Input: \"paper with the highest number of stars per hour\"\u001b[0m\u001b[36;1m\u001b[1;3mStats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The paper titled \"MeshAnything: Artist-Created Mesh Generation with Autoregressive Transformers\" by buaacyw/meshanything received the highest number of stars per hour, with a rate of 5.09 stars per hour.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Which paper received the highest number of stars per hour?\n",
      "The paper titled \"MeshAnything: Artist-Created Mesh Generation with Autoregressive Transformers\" by buaacyw/meshanything received the highest number of stars per hour, with a rate of 5.09 stars per hour.\n",
      "-----------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find information about the 'MeshAnything' project to understand its focus.\n",
      "Action: search_document\n",
      "Action Input: MeshAnything project focus\u001b[0m\u001b[36;1m\u001b[1;3mTitle:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\u001b[0m\u001b[32;1m\u001b[1;3mThe first search result provides information about the 'MeshAnything' project. It mentions that the project involves artist-created mesh generation using autoregressive transformers. This suggests that the focus of the project is on generating 3D assets that can potentially replace manually crafted assets due to their matching quality.\n",
      "\n",
      "Final Answer: The focus of the 'MeshAnything' project is on generating high-quality 3D assets using autoregressive transformers, aiming to match the quality of manually crafted assets.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "What is the focus of the 'MeshAnything' project?\n",
      "The focus of the 'MeshAnything' project is on generating high-quality 3D assets using autoregressive transformers, aiming to match the quality of manually crafted assets.\n",
      "-----------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find a paper that discusses the integration of Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS). This is likely a topic covered in recent research papers or articles in the fields of artificial intelligence, machine learning, or game theory.\n",
      "\n",
      "Action: search_document\n",
      "Action Input: \"integration of Large Language Models with Monte Carlo Tree Search\"\u001b[0m\u001b[36;1m\u001b[1;3mTitle:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\u001b[0m\u001b[32;1m\u001b[1;3mThe search results provided a relevant paper titled \"Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-38B\" by trotsky1997/mathblackbox. This paper discusses the integration of Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), specifically designed to enhance performance in complex mathematical reasoning tasks.\n",
      "\n",
      "Final Answer: The paper discussing the integration of Large Language Models with Monte Carlo Tree Search is titled \"Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-38B\" by trotsky1997/mathblackbox.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Which paper discusses the integration of Large Language Models with Monte Carlo Tree Search?\n",
      "The paper discussing the integration of Large Language Models with Monte Carlo Tree Search is titled \"Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-38B\" by trotsky1997/mathblackbox.\n",
      "-----------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find specific information about the advancements proposed in the 'VideoLLaMA 2' paper.\n",
      "\n",
      "Action: search_document\n",
      "Action Input: VideoLLaMA 2 advancements\u001b[0m\u001b[36;1m\u001b[1;3mCategories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\u001b[0m\u001b[32;1m\u001b[1;3mThe search results provide information about the advancements proposed in the 'VideoLLaMA 2' paper. The paper focuses on enhancing spatial-temporal modeling and audio understanding in video and audio-oriented tasks. This indicates improvements in how the model processes and understands the spatial and temporal aspects of video content, as well as its ability to interpret and analyze audio data.\n",
      "\n",
      "Final Answer: The 'VideoLLaMA 2' paper proposes advancements in spatial-temporal modeling and audio understanding for video and audio-oriented tasks, aiming to enhance the performance of Video Large Language Models (Video-LLMs) in these areas.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "What advancements does the 'VideoLLaMA 2' paper propose?\n",
      "The 'VideoLLaMA 2' paper proposes advancements in spatial-temporal modeling and audio understanding for video and audio-oriented tasks, aiming to enhance the performance of Video Large Language Models (Video-LLMs) in these areas.\n",
      "-----------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find information about the most recent paper published.\n",
      "\n",
      "Action: search_document\n",
      "Action Input: \"most recently published paper\"\u001b[0m\u001b[36;1m\u001b[1;3mCategories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: The most recently published paper is \"MeshAnything: Artist-Created Mesh Generation with Autoregressive Transformers\" by buaacyw/meshanything, published on 14 Jun 2024.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Which paper was published most recently?\n",
      "The most recently published paper is \"MeshAnything: Artist-Created Mesh Generation with Autoregressive Transformers\" by buaacyw/meshanything, published on 14 Jun 2024.\n",
      "-----------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find a paper that discusses language modeling and specifically addresses scalability issues. I will use the search_document function to find relevant excerpts from documents that match the query.\n",
      "\n",
      "Action: search_document\n",
      "Action Input: query='language modeling scalability'\u001b[0m\u001b[36;1m\u001b[1;3mStats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\u001b[0m\u001b[32;1m\u001b[1;3mThe search results provided a list of papers, but the most relevant one to the query about language modeling and scalability seems to be \"Scalable MatMul-free Language Modeling.\" This paper discusses the scalability of language models by proposing MatMul-free models that perform comparably to state-of-the-art Transformers but require significantly less memory, especially at large scales up to 2.7 billion parameters.\n",
      "\n",
      "Final Answer: The paper titled \"Scalable MatMul-free Language Modeling\" by ridgerchu/matmulfreellm, published on June 4, 2024, deals with language modeling and its scalability. It proposes MatMul-free models that achieve performance on-par with state-of-the-art Transformers while requiring far less memory during inference, scalable up to at least 2.7 billion parameters.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Identify a paper that deals with language modeling and its scalability.\n",
      "The paper titled \"Scalable MatMul-free Language Modeling\" by ridgerchu/matmulfreellm, published on June 4, 2024, deals with language modeling and its scalability. It proposes MatMul-free models that achieve performance on-par with state-of-the-art Transformers while requiring far less memory during inference, scalable up to at least 2.7 billion parameters.\n",
      "-----------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find information about a paper that focuses on enhancing the accuracy of Google-Proof Question Answering systems.\n",
      "\n",
      "Action: search_document\n",
      "Action Input: \"paper improving accuracy in Google-Proof Question Answering\"\u001b[0m\u001b[36;1m\u001b[1;3mStats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\u001b[0m\u001b[32;1m\u001b[1;3mThe search results provided information about various papers, but the one specifically aiming at improving accuracy in Google-Proof Question Answering is titled \"TextGrad: Automatic 'Differentiation' via Text\" by zou-group/textgrad. This paper discusses enhancing zero-shot accuracy of GPT-4o in Google-Proof Question Answering among other applications.\n",
      "\n",
      "Final Answer: The paper titled \"TextGrad: Automatic 'Differentiation' via Text\" by zou-group/textgrad aims at improving accuracy in Google-Proof Question Answering.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Which paper aims at improving accuracy in Google-Proof Question Answering?\n",
      "The paper titled \"TextGrad: Automatic 'Differentiation' via Text\" by zou-group/textgrad aims at improving accuracy in Google-Proof Question Answering.\n",
      "-----------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find out the specific categories covered by the paper titled 'TextGrad: Automatic \"Differentiation\" via Text'. To do this, I should search for excerpts from the document that mention this paper and its categories.\n",
      "\n",
      "Action: search_document\n",
      "Action Input: \"categories covered by the paper titled 'TextGrad: Automatic Differentiation via Text'\"\u001b[0m\u001b[36;1m\u001b[1;3mTitle:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\n",
      "\n",
      "Categories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The paper titled \"TextGrad: Automatic 'Differentiation' via Text\" covers the category of \"Language Modelling\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "List the categories covered by the paper titled 'TextGrad: Automatic \"Differentiation\" via Text'.\n",
      "The paper titled \"TextGrad: Automatic 'Differentiation' via Text\" covers the category of \"Language Modelling\".\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"Which paper received the highest number of stars per hour?\",\n",
    "    \"What is the focus of the 'MeshAnything' project?\",\n",
    "    \"Which paper discusses the integration of Large Language Models with Monte Carlo Tree Search?\",\n",
    "    \"What advancements does the 'VideoLLaMA 2' paper propose?\",\n",
    "    \"Which paper was published most recently?\",\n",
    "    \"Identify a paper that deals with language modeling and its scalability.\",\n",
    "    \"Which paper aims at improving accuracy in Google-Proof Question Answering?\",\n",
    "    \"List the categories covered by the paper titled 'TextGrad: Automatic \\\"Differentiation\\\" via Text'.\"\n",
    "]\n",
    "all_results=[]\n",
    "for q in queries:\n",
    "    result=rag_inference(q)\n",
    "    print(q)\n",
    "    print(result)\n",
    "    print(\"-----------------------\")\n",
    "    \n",
    "    all_results.append({'query':q,'result':result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'query': 'Which paper received the highest number of stars per hour?', 'result': 'The paper titled \"MeshAnything: Artist-Created Mesh Generation with Autoregressive Transformers\" by buaacyw/meshanything received the highest number of stars per hour, with a rate of 5.09 stars per hour.'}, {'query': \"What is the focus of the 'MeshAnything' project?\", 'result': \"The focus of the 'MeshAnything' project is on generating high-quality 3D assets using autoregressive transformers, aiming to match the quality of manually crafted assets.\"}, {'query': 'Which paper discusses the integration of Large Language Models with Monte Carlo Tree Search?', 'result': 'The paper discussing the integration of Large Language Models with Monte Carlo Tree Search is titled \"Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-38B\" by trotsky1997/mathblackbox.'}, {'query': \"What advancements does the 'VideoLLaMA 2' paper propose?\", 'result': \"The 'VideoLLaMA 2' paper proposes advancements in spatial-temporal modeling and audio understanding for video and audio-oriented tasks, aiming to enhance the performance of Video Large Language Models (Video-LLMs) in these areas.\"}, {'query': 'Which paper was published most recently?', 'result': 'The most recently published paper is \"MeshAnything: Artist-Created Mesh Generation with Autoregressive Transformers\" by buaacyw/meshanything, published on 14 Jun 2024.'}, {'query': 'Identify a paper that deals with language modeling and its scalability.', 'result': 'The paper titled \"Scalable MatMul-free Language Modeling\" by ridgerchu/matmulfreellm, published on June 4, 2024, deals with language modeling and its scalability. It proposes MatMul-free models that achieve performance on-par with state-of-the-art Transformers while requiring far less memory during inference, scalable up to at least 2.7 billion parameters.'}, {'query': 'Which paper aims at improving accuracy in Google-Proof Question Answering?', 'result': 'The paper titled \"TextGrad: Automatic \\'Differentiation\\' via Text\" by zou-group/textgrad aims at improving accuracy in Google-Proof Question Answering.'}, {'query': 'List the categories covered by the paper titled \\'TextGrad: Automatic \"Differentiation\" via Text\\'.', 'result': 'The paper titled \"TextGrad: Automatic \\'Differentiation\\' via Text\" covers the category of \"Language Modelling\".'}]\n"
     ]
    }
   ],
   "source": [
    "print(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to understand the content and context of the document to determine its purpose.\n",
      "\n",
      "Action: search_document\n",
      "Action Input: \"purpose of this document\"\u001b[0m\u001b[36;1m\u001b[1;3mCategories:  Language Modelling  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  VideoLLaMA 2: Advancing Spatial -Temporal Modeling and Audio Understanding in \n",
      "Video -LLMs  \n",
      "Authors:  damo -nlp-sg/videollama2  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  In this paper, we present the VideoLLaMA 2, a set of Video Large Language \n",
      "Models (Video -LLMs) designed to enhance spatial -temporal modeling and audio understanding \n",
      "in video and audio -oriented tasks. Stats:  318, 1.50 stars / hour  \n",
      "Categories:  Multiple -choice, Question Answering +3  \n",
      "Links:  Paper, Code\n",
      "\n",
      "Title:  MeshAnything: Artist -Created Mesh Generation with Autoregressive Transformers  \n",
      "Authors:  buaacyw/meshanything  \n",
      "Date:  14 Jun 2024  \n",
      "Description:  Recently, 3D assets created via reconstruction and generation have matched the \n",
      "quality of manually crafted assets, highlighting their potential for replacement. Stats:  417, 5.09 stars / hour  \n",
      "Categories:  Decoder  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Accessing GPT -4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self -\n",
      "refine with LLaMa -3 8B  \n",
      "Authors:  trotsky1997/mathblackbox  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  This paper introduces the MCT Self -Refine algorithm, an innovative integration of \n",
      "Large Language Models (LLMs) with Monte Carlo Tree Search (MCTS), designed to enhance \n",
      "performance in complex mathematical reasoning tasks. Stats:  279, 2.35 stars / hour  \n",
      "Categories:  Decision Making, GSM8K +2  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  TextGrad: Automatic 'Differentiation' via Text  \n",
      "Authors:  zou-group/textgrad  \n",
      "Date:  11 Jun 2024  \n",
      "Description:  Without modifying the framework, TextGrad improves the zero -shot accuracy of \n",
      "GPT -4o in Google -Proof Question Answering, yields significant relative performance gain in \n",
      "optimizing LeetCode -Hard coding problem solutions, improves prompts for reasoning, desi gns \n",
      "new druglike small molecules with desirable in silico binding, and designs radiation oncology \n",
      "treatment plans with high specificity.\n",
      "\n",
      "Stats:  485, 2.04 stars / hour  \n",
      "Categories:  Question Answering, Specificity  \n",
      "Links:  Paper, Code  \n",
      " \n",
      "Title:  Scalable MatMul -free Language Modeling  \n",
      "Authors:  ridgerchu/matmulfreellm  \n",
      "Date:  4 Jun 2024  \n",
      "Description:  Our experiments show that our proposed MatMul -free models achieve performance \n",
      "on-par with state -of-the-art Transformers that require far more memory during inference at a \n",
      "scale up to at least 2.7B parameters. Stats:  2,140, 1.98 stars / hour\u001b[0m\u001b[32;1m\u001b[1;3mThe document appears to be a collection of summaries or abstracts from various academic papers related to advancements in language modeling and other AI technologies. Each entry provides information about a specific research paper, including the title, authors, publication date, a brief description, and links to further resources.\n",
      "\n",
      "Final Answer: The purpose of this document is to provide summaries and information about recent research papers in the field of language modeling and related AI technologies.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The purpose of this document is to provide summaries and information about recent research papers in the field of language modeling and related AI technologies.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
